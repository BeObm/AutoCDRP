{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data= \"Baselines/DeepCDR-master/data/CCLE/genomic_mutation_34673_demap_features.csv\"\n",
    "df = pd.read_csv(data, index_col=False)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cell_name=list(df.iloc[:,0])\n",
    "\n",
    "cell_name\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_drug_smiles(drug_id):\n",
    "    \"\"\"\n",
    "    Retrieve the SMILES string for a given drug ID using the PubChem API.\n",
    "    \"\"\"\n",
    "    # Construct the API URL\n",
    "    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{drug_id}/property/CanonicalSMILES/json\"\n",
    "\n",
    "    # Send the API request\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the JSON response\n",
    "    json_data = response.json()\n",
    "\n",
    "    # Extract the SMILES string\n",
    "    smiles = json_data[\"PropertyTable\"][\"Properties\"][0][\"CanonicalSMILES\"]\n",
    "\n",
    "    return smiles\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smiles = get_pubchem_smiles(9826528)\n",
    "print(smiles)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import time\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def execute(name):\n",
    "\n",
    "    drug_names = []\n",
    "    drug_names.append(name)\n",
    "\n",
    "    base_url = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug\"\n",
    "\n",
    "    url_for_synonyms_to_cid = f\"{base_url}/compound/name/synonyms/json\"\n",
    "    response_pub_chem_synonyms = requests.post(url_for_synonyms_to_cid, {\"name\": name})\n",
    "    if response_pub_chem_synonyms.status_code > 202:\n",
    "        raise Exception(f\"PUBChem ({url_for_synonyms_to_cid})\\nResponse code {response_pub_chem_synonyms.status_code}\\n\"\n",
    "                        f\"{response_pub_chem_synonyms.text}\")\n",
    "    response_pub_chem_synonyms = response_pub_chem_synonyms.json()\n",
    "    cid_record = response_pub_chem_synonyms[\"InformationList\"][\"Information\"][0]\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    compound_properties = {}\n",
    "    url_for_pub_chem_smiles_iupac = f\"{base_url}/compound/cid/property/IUPACName,CanonicalSMILES/json\"\n",
    "    response_pub_chem_smiles_iupac = requests.post(url_for_pub_chem_smiles_iupac, {\"cid\": cid_record[\"CID\"]})\n",
    "    if response_pub_chem_smiles_iupac.status_code > 202:\n",
    "        raise Exception(f\"PUBChem ({url_for_pub_chem_smiles_iupac})\\n\"\n",
    "                        f\"Response code {response_pub_chem_smiles_iupac.status_code}\\n\"\n",
    "                        f\"{response_pub_chem_smiles_iupac.text}\")\n",
    "    response_pub_chem_smiles_iupac = response_pub_chem_smiles_iupac.json()\n",
    "    for params in response_pub_chem_smiles_iupac[\"PropertyTable\"][\"Properties\"]:\n",
    "        try:\n",
    "            compound_properties[params[\"CID\"]] = [params[\"CanonicalSMILES\"], params[\"IUPACName\"],\n",
    "                                                  cid_record[\"Synonym\"][0]]\n",
    "        except KeyError:\n",
    "            compound_properties[params[\"CID\"]] = [\"\", \"\", \"\"]\n",
    "    SMILES= list(compound_properties.values())[0][0]\n",
    "    return SMILES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a=execute(\"9826528\")\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_excel(\"data/CCLE/drug_id_name.xlsx\", header=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/CCLE/drugResponse_ccle.csv\", index_col=0)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp=[]\n",
    "for idx,row in df.iterrows():\n",
    "  for col in df.columns:\n",
    "    tmp.append((col,idx,df.loc[idx,col]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tmp[5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([42])\n",
      "output shape: torch.Size([42, 2])\n",
      "Epoch: 001, Loss: 0.63179, Train Acc: 0.62774, Test Acc: 0.65766\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([42])\n",
      "output shape: torch.Size([42, 2])\n",
      "Epoch: 002, Loss: 0.61723, Train Acc: 0.66766, Test Acc: 0.69369\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([42])\n",
      "output shape: torch.Size([42, 2])\n",
      "Epoch: 003, Loss: 0.61568, Train Acc: 0.68663, Test Acc: 0.72072\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n",
      "target shape: torch.Size([42])\n",
      "output shape: torch.Size([42, 2])\n",
      "Epoch: 004, Loss: 0.60069, Train Acc: 0.72255, Test Acc: 0.77477\n",
      "target shape: torch.Size([60])\n",
      "output shape: torch.Size([60, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 96\u001B[0m\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m correct \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(loader\u001B[38;5;241m.\u001B[39mdataset)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m201\u001B[39m):\n\u001B[1;32m---> 96\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     97\u001B[0m     train_acc \u001B[38;5;241m=\u001B[39m test(train_loader)\n\u001B[0;32m     98\u001B[0m     test_acc \u001B[38;5;241m=\u001B[39m test(test_loader)\n",
      "Cell \u001B[1;32mIn[5], line 74\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epoch)\u001B[0m\n\u001B[0;32m     72\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     73\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 74\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, data\u001B[38;5;241m.\u001B[39my\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m,output\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[5], line 45\u001B[0m, in \u001B[0;36mNet.forward\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     42\u001B[0m x1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([gmp(x, batch), gap(x, batch)], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     44\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x, edge_index))\n\u001B[1;32m---> 45\u001B[0m x, edge_index, _, batch, _, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpool2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m x2 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([gmp(x, batch), gap(x, batch)], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     48\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv3(x, edge_index))\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\torch_geometric\\nn\\pool\\topk_pool.py:210\u001B[0m, in \u001B[0;36mTopKPooling.forward\u001B[1;34m(self, x, edge_index, edge_attr, batch, attn)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     score \u001B[38;5;241m=\u001B[39m softmax(score, batch)\n\u001B[1;32m--> 210\u001B[0m perm \u001B[38;5;241m=\u001B[39m \u001B[43mtopk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmin_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    211\u001B[0m x \u001B[38;5;241m=\u001B[39m x[perm] \u001B[38;5;241m*\u001B[39m score[perm]\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    212\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultiplier \u001B[38;5;241m*\u001B[39m x \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultiplier \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m x\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\torch_geometric\\nn\\pool\\topk_pool.py:35\u001B[0m, in \u001B[0;36mtopk\u001B[1;34m(x, ratio, batch, min_score, tol)\u001B[0m\n\u001B[0;32m     30\u001B[0m cum_num_nodes \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(\n\u001B[0;32m     31\u001B[0m     [num_nodes\u001B[38;5;241m.\u001B[39mnew_zeros(\u001B[38;5;241m1\u001B[39m),\n\u001B[0;32m     32\u001B[0m      num_nodes\u001B[38;5;241m.\u001B[39mcumsum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     34\u001B[0m index \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(batch\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m---> 35\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcum_num_nodes\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmax_num_nodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m dense_x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mnew_full((batch_size \u001B[38;5;241m*\u001B[39m max_num_nodes, ), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m60000.0\u001B[39m)\n\u001B[0;32m     38\u001B[0m dense_x[index] \u001B[38;5;241m=\u001B[39m x\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GraphConv, TopKPooling\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch_geometric.nn import global_mean_pool as gap\n",
    "\n",
    "path = 'PROTEINS'\n",
    "dataset = TUDataset(path, name='PROTEINS')\n",
    "dataset = dataset.shuffle()\n",
    "n = len(dataset) // 10\n",
    "test_dataset = dataset[:n]\n",
    "train_dataset = dataset[n:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=60)\n",
    "train_loader = DataLoader(train_dataset, batch_size=60)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GraphConv(dataset.num_features, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv2 = GraphConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv3 = GraphConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(256, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 64)\n",
    "        self.lin3 = torch.nn.Linear(64, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.log_softmax(self.lin3(x), dim=-1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        print(\"target shape:\", data.y.shape)\n",
    "        print(\"output shape:\",output.shape)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data).max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train(epoch)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.5f}, Train Acc: {train_acc:.5f}, '\n",
    "          f'Test Acc: {test_acc:.5f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 columns passed, passed data had 2 columns",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:934\u001B[0m, in \u001B[0;36m_finalize_columns_and_data\u001B[1;34m(content, columns, dtype)\u001B[0m\n\u001B[0;32m    933\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 934\u001B[0m     columns \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_or_indexify_columns\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    935\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    936\u001B[0m     \u001B[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:981\u001B[0m, in \u001B[0;36m_validate_or_indexify_columns\u001B[1;34m(content, columns)\u001B[0m\n\u001B[0;32m    979\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_mi_list \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(columns) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(content):  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[0;32m    980\u001B[0m     \u001B[38;5;66;03m# caller's responsibility to check for this...\u001B[39;00m\n\u001B[1;32m--> 981\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    982\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(columns)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m columns passed, passed data had \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    983\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(content)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m columns\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    984\u001B[0m     )\n\u001B[0;32m    985\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_mi_list:\n\u001B[0;32m    986\u001B[0m     \u001B[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001B[39;00m\n",
      "\u001B[1;31mAssertionError\u001B[0m: 1 columns passed, passed data had 2 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 148\u001B[0m\n\u001B[0;32m    145\u001B[0m     table_data\u001B[38;5;241m.\u001B[39mappend(row_data)\n\u001B[0;32m    147\u001B[0m \u001B[38;5;66;03m# Convert tabular data to pandas DataFrame\u001B[39;00m\n\u001B[1;32m--> 148\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtable_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;66;03m# Save DataFrame to Excel file\u001B[39;00m\n\u001B[0;32m    151\u001B[0m df\u001B[38;5;241m.\u001B[39mto_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtable.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:782\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    780\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    781\u001B[0m         columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)\n\u001B[1;32m--> 782\u001B[0m     arrays, columns, index \u001B[38;5;241m=\u001B[39m \u001B[43mnested_data_to_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    783\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001B[39;49;00m\n\u001B[0;32m    784\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001B[39;49;00m\n\u001B[0;32m    785\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    786\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m    788\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    790\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m arrays_to_mgr(\n\u001B[0;32m    791\u001B[0m         arrays,\n\u001B[0;32m    792\u001B[0m         columns,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    795\u001B[0m         typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[0;32m    796\u001B[0m     )\n\u001B[0;32m    797\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:498\u001B[0m, in \u001B[0;36mnested_data_to_arrays\u001B[1;34m(data, columns, index, dtype)\u001B[0m\n\u001B[0;32m    495\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_named_tuple(data[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;129;01mand\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    496\u001B[0m     columns \u001B[38;5;241m=\u001B[39m ensure_index(data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_fields)\n\u001B[1;32m--> 498\u001B[0m arrays, columns \u001B[38;5;241m=\u001B[39m \u001B[43mto_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    499\u001B[0m columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:840\u001B[0m, in \u001B[0;36mto_arrays\u001B[1;34m(data, columns, dtype)\u001B[0m\n\u001B[0;32m    837\u001B[0m     data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mtuple\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m data]\n\u001B[0;32m    838\u001B[0m     arr \u001B[38;5;241m=\u001B[39m _list_to_arrays(data)\n\u001B[1;32m--> 840\u001B[0m content, columns \u001B[38;5;241m=\u001B[39m \u001B[43m_finalize_columns_and_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    841\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m content, columns\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:937\u001B[0m, in \u001B[0;36m_finalize_columns_and_data\u001B[1;34m(content, columns, dtype)\u001B[0m\n\u001B[0;32m    934\u001B[0m     columns \u001B[38;5;241m=\u001B[39m _validate_or_indexify_columns(contents, columns)\n\u001B[0;32m    935\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    936\u001B[0m     \u001B[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001B[39;00m\n\u001B[1;32m--> 937\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m    939\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(contents) \u001B[38;5;129;01mand\u001B[39;00m contents[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mobject_:\n\u001B[0;32m    940\u001B[0m     contents \u001B[38;5;241m=\u001B[39m convert_object_array(contents, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[1;31mValueError\u001B[0m: 1 columns passed, passed data had 2 columns"
     ]
    }
   ],
   "source": [
    "import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "# LaTeX table code\n",
    "latex_code = r'''\n",
    "\\begin{tabular}{|l|cccc|cccc|cccc|}\n",
    "\\hline\n",
    "\\multirow{2}{*}{Method} &\n",
    "  \\multicolumn{4}{c|}{Mix Experiment} &\n",
    "  \\multicolumn{4}{c|}{New drug experiment} &\n",
    "  \\multicolumn{4}{c|}{New cell-line experiment} \\\\ \\cline{2-13}\n",
    " &\n",
    "  \\multicolumn{2}{c|}{GDSC} &\n",
    "  \\multicolumn{2}{c|}{CCLE} &\n",
    "  \\multicolumn{2}{c|}{GDSC} &\n",
    "  \\multicolumn{2}{c|}{CCLE} &\n",
    "  \\multicolumn{2}{c|}{GDSC} &\n",
    "  \\multicolumn{2}{c|}{CCLE} \\\\ \\hline\n",
    " &\n",
    "  \\multicolumn{1}{c|}{PCC} &\n",
    "  \\multicolumn{1}{c|}{RMSE} &\n",
    "  \\multicolumn{1}{c|}{PCC} &\n",
    "  RMSE &\n",
    "  \\multicolumn{1}{c|}{PCC} &\n",
    "  \\multicolumn{1}{c|}{RMSE} &\n",
    "  \\multicolumn{1}{c|}{PCC} &\n",
    "  RMSE &\n",
    "  \\multicolumn{1}{c|}{PCC} &\n",
    "  \\multicolumn{1}{c|}{RMSE} &\n",
    "  \\multicolumn{1}{c|}{PCC} &\n",
    "  RMSE \\\\ \\hline\n",
    "tCNNS &\n",
    "  \\multicolumn{1}{c|}{0.9160} &\n",
    "  \\multicolumn{1}{c|}{0.0284} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   \\\\ \\hline\n",
    "GraphDRP\\_GCN &\n",
    "  \\multicolumn{1}{c|}{0.9216} &\n",
    "  \\multicolumn{1}{c|}{0.0259} &\n",
    "  \\multicolumn{1}{c|}{0.7641} &\n",
    "  0.0028 &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   \\\\ \\hline\n",
    "GraphDRP\\_GIN &\n",
    "  \\multicolumn{1}{c|}{0.9310} &\n",
    "  \\multicolumn{1}{c|}{0.0244} &\n",
    "  \\multicolumn{1}{c|}{0.7416} &\n",
    "  0.0030 &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   \\\\ \\hline\n",
    "GraphDRP\\_GAT &\n",
    "  \\multicolumn{1}{c|}{0.9270} &\n",
    "  \\multicolumn{1}{c|}{0.0250} &\n",
    "  \\multicolumn{1}{c|}{0.7880} &\n",
    "  0.0026 &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   \\\\ \\hline\n",
    "GraphDRP\\_GCN-GAT &\n",
    "  \\multicolumn{1}{c|}{0.9308} &\n",
    "  \\multicolumn{1}{c|}{0.0243} &\n",
    "  \\multicolumn{1}{c|}{0.7658} &\n",
    "  0.0028 &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   \\\\ \\hline\n",
    "GraTransDRP &\n",
    "  \\multicolumn{1}{c|}{0.9027} &\n",
    "  \\multicolumn{1}{c|}{0.0314} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   \\\\ \\hline\n",
    "AutoCDRP\\_Random &\n",
    "  \\multicolumn{1}{c|}{0.8580} &\n",
    "  \\multicolumn{1}{c|}{0.0336} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   \\\\ \\hline\n",
    "AutoCDRP &\n",
    "  \\multicolumn{1}{c|}{0.8632} &\n",
    "  \\multicolumn{1}{c|}{0.0333} &\n",
    "  \\multicolumn{1}{c|}{0.7752} &\n",
    "  0.0539 &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "  \\multicolumn{1}{c|}{} &\n",
    "   \\\\ \\hline\n",
    "\\end{tabular}\n",
    "'''\n",
    "\n",
    "# Extract tabular data from LaTeX code\n",
    "table_data = []\n",
    "for line in latex_code.split('\\n'):\n",
    "    if line.startswith('\\\\hline'):\n",
    "        continue\n",
    "    row_data = line.strip('\\\\').split('&')\n",
    "    table_data.append(row_data)\n",
    "\n",
    "# Convert tabular data to pandas DataFrame\n",
    "df = pd.DataFrame(table_data[1:])\n",
    "\n",
    "# Save DataFrame to Excel file\n",
    "df.to_excel('table.xlsx', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
